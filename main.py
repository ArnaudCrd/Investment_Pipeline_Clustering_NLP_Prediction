"""
SCRIPT PRINCIPAL : Pipeline dâ€™Analyse et Recommandation BoursiÃ¨re
Auteur : Arnaud ChÃ©ridi,

Objectif :
Ce script exÃ©cute de bout en bout un pipeline complet dâ€™analyse financiÃ¨re et de recommandation dâ€™investissement
(Buy / Hold / Sell) basÃ© sur des donnÃ©es de marchÃ©, de nouvelles Ã©conomiques et dâ€™indicateurs techniques.

Ã‰tapes du pipeline :
1. Extraction des donnÃ©es financiÃ¨res et historiques (TP1)
2. Analyse de clustering sur le risque et le rendement (TP2)
3. Classification supervisÃ©e Buy/Hold/Sell Ã  horizon 20j (TP3)
4. RÃ©gression de la valeur de clÃ´ture J+1 avec modÃ¨les classiques (TP4)
5. PrÃ©diction J+1 avec Deep Learning (TP5)
6. Scraping de news Ã©conomiques pertinentes (TP6)
7. Analyse de sentiment via modÃ¨le LLM fine-tunÃ© (TP7/TP8)
8. Analyse technique (RSI, MACD, MA/EMA) (TP_complÃ©mentaire)
9. GÃ©nÃ©ration automatique dâ€™un rapport PDF synthÃ©tique par entreprise

Structure :
- Chargement intelligent des modÃ¨les (si absents : entraÃ®nement relancÃ©)
- VÃ©rification de la complÃ©tude des fichiers
- Gestion des erreurs avec try/except
- AgrÃ©gation des signaux dans un format final pour le rapport
- GÃ©nÃ©ration PDF stylisÃ© pour chaque entreprise
"""

import os, joblib, json
import pandas as pd

from datetime import datetime, timedelta

from tensorflow.keras.models import load_model
from transformers import AutoTokenizer, AutoModelForSequenceClassification

import TP1, TP2, TP3, TP4, TP5, TP6, TP7, TP8, TP_complementaire
from generate_pdf import generate_pdf_for_company
from companies import companies


def main():
    key_companies = list(companies.values())

    with open("key_api.env", "r", encoding="utf-8") as f:
        for line in f:
            if line.strip() and not line.startswith("#"):
                key, value = line.strip().split("=", 1)
                os.environ[key] = value

    # RÃ©cupÃ©ration de la clÃ©
    NEWS_API_KEY = os.environ.get("NEWS_API_KEY")

    if not NEWS_API_KEY:
        raise ValueError("ClÃ© API manquante. Assurez-vous que key_api.env contient NEWS_API_KEY.")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. Extraction des donnÃ©es (TP1)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 1 : Extraction des donnÃ©es\n")
    TP1.scrape_ratios()
    TP1.scrape_historical()
    print(f"\nRÃ©cupÃ©ration des donnÃ©es de marchÃ©s rÃ©alisÃ©e\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. Clustering risque et rendement (TP2)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 2 : Clustering\n")
    df_ratios = pd.read_csv("historiques_entreprises/ratios_financiers.csv")

    # Clustering sur le risque
    df_risk, X_risk, labels_risk = TP2.cluster_risk_profiles(df_ratios)
    df_risk["Ticker"] = companies
    df_risk["Cluster"] = labels_risk

    # Clustering sur le rendement (corrÃ©lation)
    labels_ret, corr_ret, dist_ret = TP2.cluster_return_correlations()
    df_rendement = pd.DataFrame({
        "Ticker": companies,
        "Cluster": labels_ret
    })

    # Construction des dictionnaires de similaritÃ©

    # Clustering risque
    clustering_risque = {}
    for cl in df_risk["Cluster"].unique():
        tickers = df_risk[df_risk["Cluster"] == cl]["Ticker"].tolist()
        for t in tickers:
            clustering_risque[t] = [x for x in tickers if x != t]

    # Clustering rendement
    clustering_rendement = {}
    for cl in df_rendement["Cluster"].unique():
        tickers = df_rendement[df_rendement["Cluster"] == cl]["Ticker"].tolist()
        for t in tickers:
            clustering_rendement[t] = [x for x in tickers if x != t]

    print("\nClustering risque et rendement gÃ©nÃ©rÃ©s avec succÃ¨s.")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. Classification Buy / Hold / Sell (TP3)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 3 : Classification (achat - vente)\n")
    model_classification_path = "models/best_model_classification.pkl"
    scaler_classification_path = "models/scaler_classification.pkl"

    if not os.path.exists(model_classification_path) or not os.path.exists(scaler_classification_path):
        print("ModÃ¨le ou scaler manquant. EntraÃ®nement en cours.")
        try:
            TP3.pipeline()
        except Exception as e:
            print("Erreur lors de l'entraÃ®nement TP3")
            print("STDOUT :", e.stdout)
            print("STDERR :", e.stderr)
            raise
    else:
        print("ModÃ¨le et scaler trouvÃ©s.")

    scaler_classification = joblib.load(scaler_classification_path)
    model_classification = joblib.load(model_classification_path)
    print(f"\nModÃ¨le de classification extrait\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. RÃ©gression J+1 - ModÃ¨les Classiques (TP4)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 4 : RÃ©gression\n")

    # Dictionnaires pour stocker les modÃ¨les et scalers
    models_reg = {}
    scalers_reg = {}

    # VÃ©rifie si tous les fichiers existent, sinon lance l'entraÃ®nement
    missing_companies = []

    for company in key_companies:
        model_path = f"models/reg/best_model_{company}_reg.pkl"
        scaler_path = f"models/reg/scaler_{company}_reg.pkl"
        if not os.path.exists(model_path) or not os.path.exists(scaler_path):
            print(f"ModÃ¨le/scaler manquant pour {company}")
            missing_companies.append(company)

    if missing_companies:
        print(f"\nModÃ¨les manquants dÃ©tectÃ©s pour {len(missing_companies)} entreprise(s). EntraÃ®nement en cours...")
        for company in missing_companies:
            try:
                TP4.pipeline_one_company(symbol=company)
            except Exception as e:
                print(f"\nErreur lors de l'entraÃ®nement pour {company}")
                print("Exception :", e)
                continue
    else:
        print("Tous les modÃ¨les et scalers sont disponibles.")

    # Chargement des modÃ¨les et scalers
    for company in companies:
        try:
            model_path = f"models/reg/best_model_{company}_reg.pkl"
            scaler_path = f"models/reg/scaler_{company}_reg.pkl"
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            models_reg[company] = model
            scalers_reg[company] = scaler
        except Exception as e:
            print(f"Erreur lors du chargement pour {company} : {e}")

    print(f"\n{len(models_reg)} modÃ¨les chargÃ©s avec succÃ¨s")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. RÃ©seaux de Neurones - Deep Learning (TP5)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 5 : RÃ©seaux de neurones (Deep Learning)\n")
    # Dictionnaires pour stocker les modÃ¨les et scalers
    models_dl = {}
    scalers_dl = {}

    # VÃ©rifie si tous les fichiers existent, sinon lance l'entraÃ®nement
    missing_models = []

    for company in companies:
        model_path = f"models/dl/best_model_{company}_DL.h5"
        scaler_path = f"models/dl/scaler_{company}_DL.pkl"
        if not os.path.exists(model_path) or not os.path.exists(scaler_path):
            print(f"ModÃ¨le ou scaler manquant pour {company}")
            missing_companies.append(company)

    if missing_companies:
        print(f"\nModÃ¨les manquants dÃ©tectÃ©s pour {len(missing_companies)} entreprise(s).")
        print("DÃ©but de l'entraÃ®nement.\n")

        for symbol in missing_companies:
            print(f"EntraÃ®nement pour : {symbol}")
            try:
                TP5.compare_models(symbol=symbol)
            except Exception as e:
                print(f"\nErreur lors de l'entraÃ®nement du modÃ¨le pour {symbol}")
                print("Exception :", e)
                continue
    else:
        print("Tous les modÃ¨les et scalers deep learning sont disponibles.")

    # Chargement des modÃ¨les et scalers
    for company in companies:
        try:
            model_path = f"models/dl/best_model_{company}_DL.h5"
            scaler_path = f"models/dl/scaler_{company}_DL.pkl"
            model = load_model(model_path)
            scaler = joblib.load(scaler_path)
            models_dl[company] = model
            scalers_dl[company] = scaler
        except Exception as e:
            print(f"Erreur lors du chargement pour {company} : {e}")

    print(f"\n{len(models_dl)} modÃ¨les DL chargÃ©s avec succÃ¨s")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5 bis. Comparaison TP4 vs TP5 (RMSE) et sÃ©lection du meilleur modÃ¨le
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nPartie 5bis : Comparaison TP4 vs TP5 (RMSE) et sÃ©lection du meilleur modÃ¨le\n")

    rmse_path = "models/rmse_summary.csv"
    best_models = {}

    if not os.path.exists(rmse_path):
        print("Fichier rmse_summary.csv introuvable. Assure-toi que TP4 et TP5 ont bien exÃ©cutÃ© leurs sauvegardes.")
    else:
        df = pd.read_csv(rmse_path)

        for company in key_companies:
            subset = df[df["symbol"] == company]
            if subset.empty or subset["rmse"].isnull().any():
                print(f"DonnÃ©es incomplÃ¨tes pour {company}")
                continue

            best_row = subset.loc[subset["rmse"].idxmin()]
            source = best_row["source"]

            if source == "TP4":
                model = models_reg.get(company)
                scaler = scalers_reg.get(company)
            elif source == "TP5":
                model = models_dl.get(company)
                scaler = scalers_dl.get(company)
            else:
                print(f"Source inconnue pour {company}")
                continue

            if model is None or scaler is None:
                print(f"ModÃ¨le ou scaler introuvable pour {company} ({source})")
                continue

            best_models[company] = {
                "source": source,
                "model": model,
                "scaler": scaler,
                "rmse": best_row["rmse"]
            }

    print(f"\n{len(best_models)} modÃ¨les finaux sÃ©lectionnÃ©s")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 6. Scraping des News (TP6)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("Partie 6 : Scrapping des NEWS\n")
    name_companies = list(companies.keys())

    for company in name_companies:
        try:
            TP6.get_news_by_date(company_name = company, api_key = NEWS_API_KEY)  # ou get_news_for_company
        except Exception as e:
            print(f"Erreur pour {company} : {e}")

    print(f"\nRÃ©cupÃ©ration des news rÃ©alisÃ©e\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 7. Analyse de Sentiment - ModÃ¨le LLM (TP7/TP8)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nPartie 7 : Analyse de sentiment LLM\n")

    MODEL_DIR = "models/LLM"
    MODEL_PATH = os.path.join(MODEL_DIR, "model.safetensors")
    TOKENIZER_PATH = os.path.join(MODEL_DIR, "tokenizer_config.json")
    METRICS_PATH = os.path.join(MODEL_DIR, "metrics.json")

    # 1. VÃ©rification et entraÃ®nement si besoin
    if not os.path.exists(MODEL_PATH) or not os.path.exists(TOKENIZER_PATH):
        print("ModÃ¨le LLM non trouvÃ©. Lancement de l'entraÃ®nement.")
        try:
            TP7.pipeline()
        except Exception as e:
            print("\nUne erreur est survenue lors de l'entraÃ®nement du modÃ¨le LLM.")
            print("Exception :", e)
            raise
    else:
        print("ModÃ¨le LLM fine-tunÃ© dÃ©tectÃ©.")

    # 2. Chargement du modÃ¨le et tokenizer
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)

    print(f"\nRÃ©cupÃ©ration du modÃ¨le LLM rÃ©alisÃ©e\n")

    print("\nPartie 8 : Analyse de sentiment LLM\n")

    sentiment_history = {}

    for company in companies:
        try:
            file_path = f"news/{company}_news.json"
            if not os.path.exists(file_path):
                print(f"Fichier introuvable pour {company}")
                continue

            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)

            news = []
            for date, articles in data.items():
                for article in articles:
                    article["date"] = date
                    news.append(article)

            today = datetime.today()
            cutoff_date = today - timedelta(days=30)
            last_news = [n for n in news if "date" in n and datetime.strptime(n["date"], "%Y-%m-%d") >= cutoff_date]

            # Si moins de 5 news dans les 30 derniers jours, complÃ©ter avec les plus rÃ©centes
            if len(last_news) < 5:
                # Trier toutes les news (mÃªme au-delÃ  de 30 jours) par date dÃ©croissante
                news_sorted = sorted(news, key=lambda x: x["date"], reverse=True)
                # ComplÃ©ter avec des articles plus anciens
                for n in news_sorted:
                    if n not in last_news:
                        last_news.append(n)
                    if len(last_news) >= 5:
                        break

            texts = [item["title"] for item in last_news if "title" in item]
            dates = [item["date"] for item in last_news if "date" in item]

            if not texts or len(texts) != len(dates):
                print(f"News invalides pour {company}")
                continue

            os.makedirs("sentiments", exist_ok=True)
            preds = TP8.analyze_sentiments_by_company({company: texts}, tokenizer, model)[company]
            sentiment_labels = [ ["NÃ©gatif", "Neutre", "Positif"][p] for p in preds ]

            df = pd.DataFrame({
                "date": dates,
                "headline": texts,
                "sentiment_code": preds,
                "sentiment_label": sentiment_labels
            })

            sentiment_history[company] = df

            # sauvegarde CSV
            df.to_csv(f"sentiments/sentiments_{company}.csv", index=False)

        except Exception as e:
            print(f"Erreur pour {company} : {e}")

    print(f"\nRÃ©cupÃ©ration des sentiments rÃ©alisÃ©e\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 8. Analyse Technique (TP_complementaire)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nPartie ComplÃ©mantaire : Analyse technique ðŸ“ˆ\n")

    tech_signals = {}

    for company in key_companies:
        try:
            signals = TP_complementaire.technical_analysis(company)
            tech_signals[company] = signals
        except Exception as e:
            print(f"Erreur analyse technique pour {company} : {e}")

    print("\nAnalyse technique effectuÃ©\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 9. GÃ©nÃ©ration du Rapport PDF final
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nGÃ©nÃ©ration des rapports PDF\n")
    for ticker in key_companies:
        try:
            generate_pdf_for_company(
                ticker=ticker,
                best_models=best_models,
                model_classification=model_classification,
                scaler_classification=scaler_classification,
                tech_signals=tech_signals,
                clustering_risque=clustering_risque,
                clustering_rendement=clustering_rendement
            )
        except Exception as e:
            print(f"Erreur pour {ticker} : {e}")
    print("\nRapport GÃ©nÃ©rÃ©s\n")

if __name__ == "__main__":
    main()